---
title: "The `zoon` R package for reproducible and shareable species distribution modelling"
author: "Nick Golding, Tom August, Tim C.D. Lucas, Emiel Van Loon & Greg McInerny"
date: "21 March 2016"
bibliography: zoon_app.bib
csl: mee.csl
output: 
  pdf_document:
    fig_caption: yes
---

# Abstract

1. The diverse array of software and methodological research available for species distribution modelling (SDM) hinders independent evaluation of new methods and their dissemination to SDM users.  

2. The `zoon` R package encodes SDM analyses as a simple, but fully reproducible workflow of five steps: obtaining occurrence data, obtaining covariate data, pre-processing these data, fitting a model, and generating outputs.

3. Each of these steps is carried out by one or more community-contributed software modules maintained in a version-controlled online repository and built upon existing SDM code form R-packages and the research community.

4. `zoon` workflows are re-runnable records of the data, code and results of an entire SDM analysis and can be easily reproduced, scrutinized and extended by the whole research community.
 
5. We demonstrate `zoon` by recreating SDM analyses from two published research articles as zoon workflows, which readers can interrogate and extend.

# Introduction

<!-- The Problem -->

SDM boom & growth of methods literature [@Barbosa2015]

... reproducibility crisis in SDM.

<!-- from Greg, will need trimming down -->
In 2008, @Beale2008 suggested that “we are currently unable to build useful distribution models for many species”. 
Using null models, @Beale2008 found that chance associations between climate and species’ distributions could account for the modelled relationships which they then suggested undermined the rationale for SDM. 
Amongst the replies to this article was a re-analysis by @Araujo2009 that disputed this finding. 
@Beale2008 put the alternative results to differences in distribution data, climate data and spatial domain, but emphasised the use of different null model distributions. 
Whilst some code was provided in the original publication by @Beale2008, the following papers did not. 
The resolution of this very important discussion was hindered by the lack of data and code sharing. 

The second example comes from the study by @Elith2006, that was exceptional in its scope by comparing “16 modelling methods over 226 species from 6 regions of the world”. 
This paper provided benchmarks that both figured highly in many researchers selection of method (and software). 
However, as the data and code is not available this much needed set of benchmarks cannot be updated by the community. 
For example, when a new modelling method is produced (e.g. GRAF, Golding…) authors cannot compare the outcomes to transparent set of community contributed modelling benchmarks and standards. 
In this case, the lack of data and code sharing hinder the legacy of one of the key SDM studies to date. 

Thirdly, @Soininen2014 “assembled over 4900 published AUC (area under the curve of a receiver operating characteristic plot) values” to examine the predictability of SDM in relation to species traits. 
Having conducted this labour intensive review they suggested that researchers should “give precise reports of model calibration and evaluation methods” to enable subsequent meta-analyses. 
Relatedly, the methodological review of @Yackulic2013 investigated the use of the MAXENT algorithm in 108 articles, and have a similar concern regarding the “transparency and usefulness” in the reporting of SDM. 
In these studies there is little to no opportunity afforded by the original studies to investigate the sensitivity of the conclusion to choices in model building and data selection. 
These studies point to a far wider reduction in scientific productivity due to reporting of SDM as ‘closed knowledge’.

These three scenarios are illustrative of some of the need for the data and modelling aspects of SDM to become more repeatable, reproducible, accessible, modifiable and updateable. Each are crucial examples of the barriers to this science.
Science has to be this way and written statements of the modelling carried out do not facilitate a productive science. 
SDM, as a science, is not extensible given current working practices. 


### Solutions to these problems

The core, soluble problems are:

Difficult for new SDM users to access latest methods.

Difficult for anyone to compare methods effectively. 

Equally difficult for methods developers to disseminate their advances.


<!-- Past work towards this goal & where it falls short - the USP of ZOON and requirements -->
### Reproducible software projects

Most of the SDM users replying to a survey in 2015 (Ahmed et al. 2015) were using either MaxEnt or R as the first choice software for their analyses. 
The software market is much diverse, however, including a variety of software developed specifically for SDM (e.g. MaxEnt (), the BioMod () and dismo () packages for R, SDMtoolbox (Brown 2014), openModeller (), BioEnsembles (), ModEco ()) and software that has been appropriated for SDM studies, such as statistical software (R (), WinBugs (), OpenBugs (), Python()) and other less general software  (Domain (), Canoco (), MARS()). 

Reproducibility (and the issues discussed above) were not a primary requirement of these software, and whilst some have the capacity for an analysis to be repeated, many do not. 
Software such as BioMod, OpenModeller, BioEnsembles, ModEco were developed to enable users to carry out analyses with multiple models.

The BIOVEL software [@DeGiovanni2015] is an exception, sharing many of the general principles of ZOON, such as the increased accessibility to science via community contributed resources and increased sustainability by creating an e-infrastructure for this science.
There are other workflow systems that can be used to wrap around SDM analyses (e.g. Kepler, Vis-Trails, Taverna), yet there has not been a large uptake by the community.
Perhaps this is because of the unfamiliarity or assumed complexity of these tools.

The SDM package [@Naimi2016] implements a number of modern SDM approaches in a simple modular framework.
This package also has some functionality for users to incorporate new modelling methods into their analyses.
There is, however still a signifiact technical barrier to those wishing to incorporate their methods, and to share them more widely.

### The ZOON project

The ZOON project takes a different approach, instead defining only the core architecture of workflows, and interfacing with an open repository of community-contributed software modules.
This paper introduces version 0.4-22 of the `zoon` R package, which encodes the majority of this functionality.
First, we describe the modular structure of zoon workflows and demonstrate how completed `zoon` workflows can be shared, evaluated and extended.
Then we illustrate these concepts, and the contribution we hope `zoon` will make to SDM research, by recreating and extending two recent SDM analyses using `zoon` workflows.

<!-- The Solution: ZOOOOOON!  -->
# The `zoon` R package

Versions 0.4-22 and later of the `zoon` R package can be installed directly from CRAN.

### Constructing a `zoon` workflow

The `zoon` R package encodes SDM analyses as a simple workflow of five steps: obtaining occurrence data, obtaining covariate data, pre-processing these data, fitting a model, and generating outputs.
Each of these steps is carried out by one or more community-contributed software modules.

Figure \ref{fig:workflows} illustrates the structure of a `zoon` workflow.

```{r, echo = FALSE, fig.cap = "The modular SDM structure encoded by a zoon workflow. A) Flow diagram representing the module types. B) The required inputs and outputs for each module types (full details given in the `zoon` vignette 'Building a module'). C) Chaining and listing modules of the same type. D) The structure of a workflow object.\\label{fig:workflows}"}

# four panel plot, no margins
par(mar = c(1, 1, 2, 1),
    mfrow = c(2, 2))

# placeholder plots for each panel
for (i in 1:4) {
  
  # set up plotting window
  plot.new()
  plot.window(0:1, 0:1)

  # grey rectangle (no background in vector pdf?)
  rect(-1, -1, 2, 2, col = grey(0.9), border = NA)

  # text over the top
  text(0.5, 0.5, 'PLACEHOLDER',
       col = grey(0.3),
       cex = -13,
       xpd = NA)
  
  # add a panel letter
  mtext(text = LETTERS[i],
        side = 3,
        line = 0.5,
        adj = 0)  
}
```

#### Module types

* *Occurrence* - Usually presence-absence data or presence-only data, though abundance data is also used.
* *Covariates* - Predictor variables or covariates (typically environmental covariates) are required and the values of these covariates, at the locations of the occurrence data, must be extracted.
* *Process* - Processes  applied to the occurrence and covariate data. These processes include data cleaning, data thinning to account for spatial biases, feature selection using PCA or association tests and the splitting of data into training and test sets or cross validation folds.
* *Model* - Once the data has been suitable manipulated a model is fitted to estimate the relationships between the covariates and occurrence data. These models include simple statistical models such as GLMs as well as modern, flexible machine-learning methods such as MaxEnt and boosted regression trees.
* *Output* - The predictive power and goodness of fit must be assessed and the model parameters or response curves must be examined. The model is likely to be used to predict species occurrence, either in the vicinity of the occurrence data or elsewhere, or into the past or future.

This structure defines how `zoon` approaches SDM. 
For each of these steps, the user selects one or more 'modules' and combined them in a call to `workflow`.
To combine multiple modules of the same type we provide the `Chain` command.
For occurrence and covariate modules, this command takes multiple modules and simply combines the data acquired by each module.
Chained process models are run sequentially.
For example if a user wants to generate background or pseudo absence data and then split the data into crossvalidation folds, modules implementing these two seperate process would be chained in that order.
Finally, chained output modules are simply all run seperately allowing the user to create multiple maps and summary figures, calcualte performance metrics and create other model outputs in one workflow.
Model modules cannot be chained.

This framework facilitates rapid dissemination of novel SDM methodologies by lowering the bar to creating research software.
`zoon` workflows are re-runnable records of the data, code and results of an entire SDM analysis and can be easily reproduced, scrutinized and extended by the whole research community.






ZOON allows users to make use of modules whether they are using a ZOON workflow or not. 
Users can create new modules for any modelling method and integrate it into another analysis. 
Unlike R itself, there are far reduced overheads on creating a package...


### Inspecting, sharing and extending a `zoon` workflow

Structure of workflow objects:

* code (call and modules used)
* output of each module; data, results and intermediate steps
* recording the session info and package and module versions

Extra stuff workflows do (handle cross validation, run parallel methods/data comparisons).

Things you can do to workflows: 

* visualise the structure
* execute whole thing from scratch (grabs new data from web)
* execute from part way through

Include a figure visualising the structure of the workflow object and how it can be adopted in the ChangeWorkflow function (corresponding to an example below?).

### Example Applications

We demonstrate the `zoon` R package by recreating two SDM analyses from published research articles and extending them.
Workflow objects created by these analyses can be accessed at [http://figshare.com/articles/zoon_applications_paper_workflows](http://figshare.com/articles/zoon_applications_paper_workflows).
We encourage readers to download, interrogate and alter these workflows for themselves.
Full code and metadata for all of the modules used in the examples below, can be found at [https://github.com/zoonproject/modules/R](https://github.com/zoonproject/modules/R)

#### Example 1. Modelling the distribution of ???

??? constructed a species distribution model for ??? using ???.

Such a model can be re-constructed as a `zoon` workflow using modules which are already available in the software repository:

```{r, eval=FALSE}
carruthers_et_al <- workflow(
    occurrence = ...,
    covariate = ...,
    process = ...,
    model = ...,
    output = ...)
```

The resulting workflow contains all the c
Some tweak we did to it:



```{r, eval=FALSE}
carruthers_et_al_interactive <- ReRunWorkflow(
    carruthers_et_al,
    output = InteractiveMap)
```

![The interactive map module overlay the raw data and predicted distribution, allowing users to interactivly explore thier results.](./figs/interactive_map.png)

Some plottable results of this analysis 

#### Repeating a MEE methods comparison 

Proposed paper:

>Merow & Silander (2014) A comparison of Maxlike and Maxent for modelling species distributions. *Methods in Ecology and Evolution*

This is a method that saw a lot of discussion and for which more experiments could be useful.

Possible experiments:
* evaluating with different criteria (e.g. deviance or pseudo-r-squared which measure calibration capacity)
* fitting the same models with GBIF data and evaluating against the BBS PA data,
* fitting/evaluating on spatially-stratified holdout data
* fitting the models with other species

(choose only one of these)


One of the modules we had to write (simpler than the MaxLike one!):

```{r, eval=FALSE}
CarolinaWrenPO <- function() {
  
  # load maxlike and the dataset into this environment
  zoon::GetPackage('maxlike')
  data(carw, envir = environment())
  occ <- na.omit(carw.data$pa.data)

  # keep only presences
  occ <- occ[occ$y == 1, ]
  
  # build the occurrence dataset and return
  data.frame(longitude = occ$Lon,
             latitude = occ$Lat,
             value = occ$y,
             type = 'presence'),
             fold = 1)
  
}
```

What the workflow looks like:

```{r, eval=FALSE}
merow_and_silander <- workflow(
    occurrence = CarolinaWrenPO,
    covariate = ...,
    process = ...,
    model = list(MaxEnt, MaxLike),
    output = ...)
```

So we ran it again with disc-based spatial stratification:

```{r, eval=FALSE}
merow_and_silander_spatial <- ReRunWorkflow(
    merow_and_silander,
    process = Chain(..., PartitionDisc))
```

### Future developments

Tutorials on how to create workflows and modules, as well as full technical details for module developers, are provided as vignettes distributed with `zoon`.

The `zoon` packages provides solutions to some of the technical barriers to the ultimate goal of more open, productive, reproducible SDM research.
Achieving this goal will also depend on overcoming the social hurdle of developing a common tool for comparing and quantitatively evaluating SDMs.

This will require achieving a critical mass of `zoon` modules, so that there is an incentive for species distribution modellers to use the software, and a critical mass of users, so that there is an incentive for SDM methods developers to encode their proposed methods as modules in the community repo.
At this point `zoon` will provide a common environment in which to evaluate SDM methods and enable the SDM research community to make evidence-based decisions about best practice and the goals for development of the field.

In order to facilitate this social aspect, future work will develop an online platform to enable exploring contributed modules and workflows.
This platform will also provide an online space to discuss, and openly evaluate, proposed best practices in SDM.
The zoon R package therefore represents a step towards a more reproducible ecosystem of SDM software. 


### References


