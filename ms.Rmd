---
title: "The `zoon` R package for reproducible and shareable species distribution modelling"
author: "Nick Golding, Tom August, Tim C.D. Lucas, Emiel Van Loon & Greg McInerny"
bibliography: zoon_app.bib
csl: mee.csl
output:
  pdf_document:
    fig_caption: yes
    includes:  
      in_header: latex_preamble.tex
---

# Abstract

1. The diverse array of software and methodological research available for species distribution modelling (SDM) hinders independent evaluation of new methods and their dissemination to SDM users.  

2. The `zoon` R package encodes SDM analyses as a simple, but fully reproducible workflow of five steps: obtaining occurrence data, obtaining covariate data, pre-processing these data, fitting a model, and generating outputs.

3. Each of these steps is carried out by one or more community-contributed software modules maintained in a version-controlled online repository and built upon existing SDM code form R-packages and the research community.

4. `zoon` workflows are re-runnable records of the data, code and results of an entire SDM analysis and can be easily reproduced, scrutinized and extended by the whole research community.
 
5. We demonstrate `zoon` by recreating SDM analyses from two published research articles as zoon workflows, which readers can interrogate and extend.


```{r knitrOpts, echo = FALSE, cache = FALSE, eval = TRUE}
# set up knitr options
knitr::opts_chunk$set(fig.path = 'figs/',
               message = FALSE,
               warning = FALSE,
               dev = c('png'),
               cache = TRUE)
```

```{r raster_dir, echo = FALSE, cache = FALSE, eval = TRUE}
# set a place for the rasters to be downloaded to (to stop them being grabbed
# again each time)
raster_dir <- './raster_data'
if (!dir.exists(raster_dir)) dir.create(raster_dir)
options("rasterDataDir" = raster_dir)
```

# Introduction

<!-- The Problem -->

Like many areas of quantitative science, Species Distribution Modelling SDM has grown rapidly [@Barbosa2015] - fuelled by the availability of diverse modelling software and data.
Over the last 20 years, SDM has developed into a very large research community and vast literature, and is now one of “the most widely-reviewed topics in the ecological literature” (Araújo & Peterson XXXX).
Most of the software that enables SDM research, and that of other computational sub-disciplines, focuses on the analytical tasks of science (such as modelling and statistics) rather than tasks that are essential to the scientific enterprise, such as communication and producing reproducible outputs. 

This has presented computational science with a very modern version of the reproducibility problem as computational research is largely inaccessible ().
If research materials and outputs are shared, they are rarely in a readily modifiable or extensible format despite the great potential for distributing these resources digitally (e.g. Figshare, GitHub).
The ZOON R package aims to address these issues for Species Distribution Modelling by allowing users to encode SDM analyses as workflows comprised of independently executable modules.
The module-workflow structure offers a format by which scientists can more easily to create and share components of their analysis, and then access, modify, reuse and combine the components of others (see below and Figure 1). 

To date, the lack of sharing has reduced the capacity for innovation and validation in SDM, as well as its capacity for self-correction ().
For example, a fundamental dispute over the ability of SDM to detect environmental associations (Beale et al. 2008, Araujou et al. 2009, Beale et al. 2009) was left unresolved as only code in the original publication was published (Beale et al. 2008). Without the resources being made open, the critical differences in these analysis are assumed rather than proven. 

A second example comes from Elith et al. (2006), who reported a study of exceptional scope(“16 modelling methods over 226 species from 6 regions of the world”).
The modelling benchmarks that were reported have been highly influential, yet cannot be updated as the code and data were not shared.
The community cannot update or modify the benchmarks when new modelling method is produced (e.g. GRAF, Golding…).
A third example comes from meta-analyses () and methodological reviews (), which require laborious searches of publications in the absence of shared code and modelling outputs.
These findings cannot be turned into reanalyses that would yield truly informative methodological conclusions. 

These three scenarios are illustrative of some of the need for the data and modelling aspects of SDM to become more repeatable, reproducible, accessible, modifiable and updateable. Each are crucial examples of the barriers to this science.

Science has to be this way and written statements of the modelling carried out do not facilitate a productive science. 
SDM, as a science, is not extensible given current working practices. 


### Solutions to these problems

The core, soluble problems are:

Difficult for new SDM users to access latest methods.

Difficult for anyone to compare methods effectively. 

Equally difficult for methods developers to disseminate their advances.


<!-- Past work towards this goal & where it falls short - the USP of ZOON and requirements -->
### Reproducible software projects

Most of the SDM users replying to a survey in 2015 (Ahmed et al. 2015) were using either MaxEnt or R as the first choice software for their analyses. 
The software market is much diverse, however, including a variety of software developed specifically for SDM (e.g. MaxEnt (), the BioMod () and dismo () packages for R, SDMtoolbox (Brown 2014), openModeller (), BioEnsembles (), ModEco ()) and software that has been appropriated for SDM studies, such as statistical software (R (), WinBugs (), OpenBugs (), Python()) and other less general software  (Domain (), Canoco (), MARS()). 

Reproducibility (and the issues discussed above) were not a primary requirement of these software, and whilst some have the capacity for an analysis to be repeated, many do not. 
Software such as BioMod, OpenModeller, BioEnsembles, ModEco were developed to enable users to carry out analyses with multiple models.

The BIOVEL software [@DeGiovanni2015] is an exception, sharing many of the general principles of ZOON, such as the increased accessibility to science via community contributed resources and increased sustainability by creating an e-infrastructure for this science.
There are other workflow systems that can be used to wrap around SDM analyses (e.g. Kepler, Vis-Trails, Taverna), yet there has not been a large uptake by the community.
Perhaps this is because of the unfamiliarity or assumed complexity of these tools.

The SDM package [@Naimi2016] implements a number of modern SDM approaches in a simple modular framework.
This package also has some functionality for users to incorporate new modelling methods into their analyses.
There is, however still a signifiact technical barrier to those wishing to incorporate their methods, and to share them more widely.

### The ZOON project

The ZOON project takes a different approach, instead defining only the core architecture of workflows, and interfacing with an open repository of community-contributed software modules.
Users can create new modules for any modelling method and integrate it into another analysis. 

Similarly to programming languages such as R and Python, facilitating wider development of software will enable the whole research community to develop the software that it requires, rather than rely on the developers of the software they use to do it for them.
Unlike software packages for programming languages however, the ZOON project enforces a modular structure that ensures interoperability between contributed software modules.
This also helps to lower the bar for creating modules (each module is simply an R function with a set of required inputs and outputs) and facilitates automated testing of modules ot ensure software quality .

This paper introduces version 0.4-22 of the `zoon` R package, which encodes the majority of this functionality.
First, we describe the modular structure of zoon workflows and demonstrate how completed `zoon` workflows can be shared, evaluated and extended.
Then we illustrate these concepts, and the contribution we hope `zoon` will make to SDM research, by recreating and extending two recent SDM analyses using `zoon` workflows.

<!-- The Solution: ZOOOOOON!  -->
# The `zoon` R package

Versions 0.4-22 and later of the `zoon` R package can be installed directly from CRAN.

### Constructing a `zoon` workflow

The `zoon` R package encodes SDM analyses as a simple workflow of five steps: obtaining occurrence data, obtaining covariate data, pre-processing these data, fitting a model, and generating outputs.
Each of these steps is carried out by one or more community-contributed software modules.
For each of these steps, the user selects one or more 'modules' and combined them in a call to `workflow`.

Figure \ref{fig:workflows} illustrates the structure of a `zoon` workflow.

```{r plotzoonoverview, echo = FALSE, fig.show = 'hide', fig.height = 9, dpi = 300}

# the figures for this panel are generated in powerpoint (I know, I know, but it's quick and easy) and saved in the figs folder.
# the powerpoint file itself is not version controlled, but can be access here: https://www.dropbox.com/s/afjpv8v6na9y56e/diagrams.pptx?dl=0

# four panel plot
par(mfrow = c(2, 2))

# plot the saved image in the first panel
library(raster)
r <- brick('figs/workflow_basic.png')
par(mar = c(1, 1, 2, 1))
plotRGB(r, maxpixels = Inf)

# add a panel letter
# this is an awful hack and completely contingent on the screenshot size :/
text(40, 940, labels = LETTERS[1],
      xpd = NA,
     cex = 1.2)  

par(mar = c(1, 1, 2, 1))
# placeholder plots for each panel
for (i in 2:4) {
  
  # set up plotting window
  plot.new()
  plot.window(0:1, 0:1)

  # grey rectangle (no background in vector pdf?)
  rect(-1, -1, 2, 2, col = grey(0.9), border = NA)

  # text over the top
  text(0.5, 0.5, 'PLACEHOLDER',
       col = grey(0.3),
       cex = -13,
       xpd = NA)
  
  # add a panel letter
  mtext(text = LETTERS[i],
        side = 3,
        line = 0.5,
        adj = 0)  
}
```
![The modular SDM structure encoded by a zoon workflow. A) Flow diagram representing the module types. B) The required inputs and outputs for each module types (full details given in the `zoon` vignette 'Building a module'). C) Chaining and listing modules of the same type. D) The structure of a workflow object.\label{fig:workflows}](./figs/plotzoonoverview-1.png)

#### Module types

* *Occurrence* - Usually presence-absence data or presence-only data, though abundance data is also used.
* *Covariates* - Predictor variables or covariates (typically environmental covariates) are required and the values of these covariates, at the locations of the occurrence data, must be extracted.
* *Process* - Processes  applied to the occurrence and covariate data. These processes include data cleaning, data thinning to account for spatial biases, feature selection using PCA or association tests and the splitting of data into training and test sets or cross validation folds.
* *Model* - Once the data has been suitable manipulated a model is fitted to estimate the relationships between the covariates and occurrence data. These models include simple statistical models such as GLMs as well as modern, flexible machine-learning methods such as MaxEnt and boosted regression trees.
* *Output* - The predictive power and goodness of fit must be assessed and the model parameters or response curves must be examined. The model is likely to be used to predict species occurrence, either in the vicinity of the occurrence data or elsewhere, or into the past or future.


#### Lists and Chains

To combine multiple modules of the same type we provide the `Chain` command.
For occurrence and covariate modules, this command takes multiple modules and simply combines the data acquired by each module.
Chained process models are run sequentially.
For example if a user wants to generate background or pseudo absence data and then split the data into crossvalidation folds, modules implementing these two seperate process would be chained in that order.
Finally, chained output modules are simply all run seperately allowing the user to create multiple maps and summary figures, calcualte performance metrics and create other model outputs in one workflow.
Model modules cannot be chained.


Many SDM analyses require running similar workflow in parallel. 
In applied settings this may be running the same analysis for multiple species.
In methodological work, it is important to compare new methods or models to benchmarks.
To divide a `zoon` workflow into multiple parallel analyses the `list` function is used.
`list` can be used to split the analysis at any point: listing multiple occurrence modules together will run the workflow on different occurrence datasets while listing multiple model modules will fit different models to a shared, identical dataset but then apply output modules to each model separately.

The complete workflow, with multiple modules defined with the `Chain` function and parallel analyses being defined with the `list` function can be visualised by calling `plot` with the workflow object as it's argument.
This displays the names of all modules and the broader structure of the workflow as well as displaying which modules are not available in the online repository (Figure ).

#### Crossvalidation

`workflow` sensibly handles cross-validation.
Process modules are used to split the data into a training and test set or into multiple folds so that each fold in turn will be held back and used as the test for the predictive ability of any fitted models.
The same test/train splits will be used for each analysis if the multiple models or methods are being used so that model performance measures are comparable.
Furthermore, the test/train splits are saved along with the workflow so that other researchers adding to a workflow can make fair comparisons. 
After models are fitted to these subsets of the data, they are also fitted to the entire dataset as this will provide the best models for predictions from further new data.



### Inspecting, sharing and extending a `zoon` workflow


Structure of workflow objects:

* code (call and modules used)
* output of each module; data, results and intermediate steps
* recording the session info and package and module versions

`zoon` workflows are re-runnable records of the data, code and results of an entire SDM analysis and can be easily reproduced, scrutinized and extended by the whole research community.
A zoon workflow returns an object of class `zoonWorkflow`.
This object contains all the information needed to reproduce the analysis.
This includes the original call, a record of the packages and modules used and their versions when the analysis was run as well as all the data and fitted models.

A workflow is reproducible, reusable and alterable by way of the functions `RerunWorkflow` and `ChangeWorkflow`.
Using `RerunWorkflow` a workflow object can be run from scratch or from part way though the analysis to avoid computationally slow steps.
`ChangeWorkflow` takes as it's arguments a workflow object and new selections for any or all of the workflow steps.
The workflow is then rerun from the first altered step.



Things you can do to workflows: 

* visualise the structure
* execute whole thing from scratch (grabs new data from web)
* execute from part way through

`zoon` provides functionality to quickly update an existing workflow object (even one created by someone else) by switching out modules.


Include a figure visualising the structure of the workflow object and how it can be adopted in the ChangeWorkflow function (corresponding to an example below?).

#### Building modules

Modules are simply R function definitions, with a set of required inputs and outputs.
For example the`Bioclim` module, which uses the `raster` R package [@raster] to download the widely used bioclim [@Hijmans2005] covariate layers in the correct format, is (excluding some error-handling code for brevity) defined as:

```{r bioclimmodule, eval = FALSE}
Bioclim <- function (extent = c(-180, 180, -90, 90),
                     resolution = 10,
                     layers = 1:19) {
    world <- getData('worldclim', var = 'bio', res = resolution)
    world <- world[[layers]]
    cropped <- crop(world, extent(extent))
    return (cropped)
  }
```

This function meets the minimal requirements of a *covariate* module (see Figure \ref{fig:workflows} Panel B); returning a `Raster\*` object of the correct dimensions.

As long as a valid module function is defined in an R session, it can be used in workflows in combination with modules downloaded from the ZOON module repository.
Whilst this makes it easy to develop modules locally, the strength of `zoon` comes from the ability to upload modules to the online repository so that others can access them.

To do this, it first is necessary to provide additional metadata including the module tile and description, module type, author name and definitions for any non-mandatory arguments.
`zoon` provides the function `BuildModule()` to facilitate entering this metadata and checking that it matches the module.

The `zoon` vignette *Building modules* provides a detailed tutorial for building modules of each type.

### Example Applications

We demonstrate the `zoon` R package by recreating two SDM analyses from published research articles and extending them.
Workflow objects created by these analyses can be accessed at [http://figshare.com/articles/zoon_applications_paper_workflows](http://figshare.com/articles/zoon_applications_paper_workflows).
We encourage readers to download, interrogate and alter these workflows for themselves.
Full code and metadata for all of the modules used in the examples below, can be found at [https://github.com/zoonproject/modules/R](https://github.com/zoonproject/modules/R)

#### Example 1. Modelling the potential distribution of nine-banded armadillo in the USA

@Feng2015 constructed a MaxEnt species distribution model for nine-banded armadillo in the USA using presence-only data on the species' current distribution, and the bioclim [@Hijmans2005] set of environmental correlates.
This model was then used to predict areas in the Americas which may be suitable for the species to become established. 

Such a model can be quickly and easily re-constructed as a `zoon` workflow using modules available in the ZOON module repository.
@Feng2015 used a combination of occurrence data from GBIF, and additional occurrence data manually collected from the published literature.
Unfortunately the latter data have not been made publically available, so here we use only data from GBIF.
If the the additional data had been made available it would be straightforward to incorporate them, for example using the `LocalOccurrenceData` module.

```{r loadzoon, eval = TRUE, echo = FALSE, cache = FALSE}
# Keep cache = FALSE. Not supposed to cache chunks with library()
#  I assume we want this not echoed.
library(zoon)

set.seed(1633)

```


```{r fengworkflow, eval = TRUE, dpi = 300, fig.show = 'hide', results = 'hide', message = FALSE, fig.height = 9, fig.width = 9}
Feng_Papes <- 
  workflow(occurrence = SpOcc('Dasypus novemcinctus',
                              extent = c(-130, -20, -60, 60)),
            covariate = Bioclim(extent = c(-130, -20, -60, 60),
                                layers = c(1:4, 6, 9, 10, 12, 15)),
              process = Chain(Clean, 
                              MESSMask,  
                              Background(n = 10000, bias = 200), 
                              Crossvalidate(k = 5)),
                model = MaxEnt,
               output = PrintMap)
```

![Map of the presence data (red), background data (black) and the MaxEnt relative probability of occurrence generated by the `PrintMap` module in the workflow `Feng_Papes`. White areas are masked due to being in the sea or outside the MESS mask. \label{fig:fengmap}](./figs/fengworkflow-1.png)

The resulting workflow contains all the code required to re-run the workflow, the input data and the results of executing each module.
The object `Feng_Papes` could therefore be saved as a binary file and shared as a reproducible representation of this research.

Next, we update the workflow to produce an interactive map enabling anyone to inspect the data and  predictions on a zoomable map, and to inspect the response curves of the fitted model. These outputs are shown in Figure \ref{fig:interactive}.

```{r fengChangeWorkflow, eval = TRUE, fig.show = 'hide'}
Feng_Papes_Update <- 
  ChangeWorkflow(workflow = Feng_Papes,
                   output = Chain(InteractiveMap, 
                                  ResponseCurve(cov = 1)))
```

```{r combinefengupdate, eval = TRUE, echo = FALSE, dpi = 300, fig.show = 'hide', fig.height = 3.2}
# combine the printed map and first effect plot

# load both images
r_map <- brick('figs/interactive_map.png')
r_resp <- raster('figs/fengChangeWorkflow-2.png')
r_resp <- brick(r_resp, r_resp, r_resp)

# set up layout so that heights are the same for both panels
plot_height <- min(nrow(r_map), nrow(r_resp))

# get rescaling factor for each
rescale_map <- plot_height / nrow(r_map)
rescale_resp <- plot_height / nrow(r_resp)

# get widths
width_map <- ncol(r_map) * rescale_map
width_resp <- ncol(r_resp) * rescale_resp

# set up layout (maximum total of 200 columns) with a gap in between
# mar won't work for these
gap <- 2
widths <- c(width_map, width_resp)
widths <- round(widths * ((200-gap) / sum(widths)))
widths <- c(widths[1], gap, widths[2])
mat <- matrix(rep(1:3, widths),
              nrow = 1)
layout(mat)

# plot interactive map
plotRGB(r_map, maxpixels = Inf)

# add a panel letter
mtext(text = 'A',
        side = 3,
        line = -3,
        adj = 0)  

# gap
plot.new()

# plot the response curve
plotRGB(r_resp, maxpixels = Inf,
        scale = max(maxValue(r_resp)))

# add a panel letter
mtext(text = 'B',
        side = 3,
        line = -3,
        adj = 0)  

```

![The outputs of the updated workflow object `Feng_Papes_Update`. A) A screenshot of the interactive map produced by the `InteractiveMap`, displaying raw occurrence data and predicted distribution over a global map, allowing users to interactively explore their results. B) A response curve produced by the `ResponseCurve` for the first covariate, bio1. \label{fig:interactive}](./figs/combinefengupdate-1.png)

<!-- add the original and the response curves to this figure too -->

#### Example 2. Evaluating MaxLike

@Royle2012 proposed a model for fitting SDMs to presence-only data, which they suggest is able to estimate the absolute (rather than relative) probability of species presence in each grid cell.
This model and the associated claims have been the subject of several research articles evaluating the model against both real-world and simulated datasets [@Fitzpatrick2013;@Merow2014;@Hastie2013;@Phillips2013].

In this example we illustrate how `zoon` can help contribute to discussions such as these by enabling rapid evaluation of a new method against a variety of datasets and test procedures.

For this example, it was necessary to create three new modules: two to load the presence/absence and presence-only Carolina Wren datasets from @Royle2012; and one to implement the MaxLike model.

<!--
Possible experiments:
* evaluating with different criteria (e.g. deviance or pseudo-r-squared which measure calibration capacity)
* fitting the same models with GBIF data and evaluating against the BBS PA data,
* fitting/evaluating on spatially-stratified holdout data
* fitting the models with other species
(choose only one of these)
-->

All of these have now been uploaded to the ZOON modules repository under the names `CarolinaWrenPO`, `CarolinaWrenPA`, `CarolinaWrenRasters` and `MaxLike`.

What the workflow looks like:

```{r merowworkflow, eval = TRUE}
Merow_Silander <- workflow(
    occurrence = CarolinaWrenPO,
    covariate = CarolinaWrenRasters,
    process = Background(n = 10000),
    model = list(LogisticRegression, MaxEnt, MaxLike),
    output = Chain(PerformanceMeasures, PrintMap))
```


```{r merowworkflow, eval = FALSE}

Merow_Silander <- workflow(
    occurrence = CarolinaWrenPO,
    covariate = CarolinaWrenRasters,
    process = Chain(Transform(trans = 'square',
                                 replace = FALSE), 
                       Background(n = 10000)),
    model = list(LogisticRegression, MaxEnt, MaxLike),
    output = Chain(PerformanceMeasures, PointBiserialCorr, PrintMap, Coefficients))
```

So we ran it again with disc-based spatial stratification:

```{r merowChangeWorkflow, eval = FALSE}
Merow_Silander_Spatial <- ChangeWorkflow(
    merow_and_silander,
    process = Chain(..., PartitionDisc))
```

### Future developments

Tutorials on how to create workflows and modules, as well as full technical details for module developers, are provided as vignettes distributed with `zoon`.

The `zoon` packages provides solutions to some of the technical barriers to the ultimate goal of more open, productive, reproducible SDM research.
Achieving this goal will also depend on overcoming the social hurdle of developing a common tool for comparing and quantitatively evaluating SDMs.

This will require achieving a critical mass of `zoon` modules, so that there is an incentive for species distribution modellers to use the software, and a critical mass of users, so that there is an incentive for SDM methods developers to encode their proposed methods as modules in the community repo.
At this point `zoon` will provide a common environment in which to evaluate SDM methods and enable the SDM research community to make evidence-based decisions about best practice and the goals for development of the field.

In order to facilitate this social aspect, future work will develop an online platform to enable exploring contributed modules and workflows.
This platform will also provide an online space to discuss, and openly evaluate, proposed best practices in SDM.
The zoon R package therefore represents a step towards a more reproducible ecosystem of SDM software. 


### References


