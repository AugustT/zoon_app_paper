---
title: "The `zoon` R package for reproducible and shareable species distribution modelling"
author: "Nick Golding, Tom August, Tim C.D. Lucas, Emiel Van Loon & Greg McInerny"
date: "4 March 2016"
output: 
  pdf_document:
    fig_caption: yes
---

### Abstract

1. The diverse array of software and methodological research available for species distribution modelling (SDM) hinders independent evaluation of new methods and their dissemination to SDM users.  

2. The `zoon` R package encodes SDM analyses as a simple, but fully reproducible workflow of five steps: obtaining occurrence data, obtaining covariate data, pre-processing these data, fitting a model, and generating outputs.

3. Each of these steps is carried out by one or more community-contributed software modules maintained in a version-controlled online repository and built upon existing SDM code form R-packages and the research community.

4. `zoon` workflows are re-runnable records of the data, code and results of an entire SDM analysis and can be easily reproduced, scrutinized and extended by the whole research community.
 
5. We demonstrate `zoon` by recreating SDM analyses from two published research articles as zoon workflows, which readers can interrogate and extend.

### Introduction

<!-- The Problem -->
Reproducibility crisis in species distribution modelling (SDM).
Difficult for new SDM users to access latest methods.
Difficult for anyone to compare methods effectively. 
Equally difficult for methods developers to disseminate their advances.

<!-- from Greg: -->
In 2008, Beale et al. (2008) suggested that “we are currently unable to build useful distribution models for many species”. 
Using null models, Beale et al. (2008) found that chance associations between climate and species’ distributions could account for the modelled relationships which they then suggested undermined the rationale for SDM. 
Amongst the replies to this article was a re-analysis by Araujou et al. (2009) that disputed this finding. 
Beale et al. (2008) put the alternative results to differences in distribution data, climate data and spatial domain, but emphasised the use of different null model distributions. 
Whilst some code was provided in the original publication by Beale et al. (2008), the following papers did not. 
The resolution of this very important discussion was hindered by the lack of data and code sharing. 

The second example comes from the study by Elith et al. (2006), that was exceptional in its scope by comparing “16 modelling methods over 226 species from 6 regions of the world”. This paper provided benchmarks that both figured highly in many researchers selection of method (and software). However, as the data and code is not available this much needed set of benchmarks cannot be updated by the community. For example, when a new modelling method is produced (e.g. GRAF, Golding…) authors cannot compare the outcomes to transparent set of community contributed modelling benchmarks and standards. In this case, the lack of data and code sharing hinder the legacy of one of the key SDM studies to date. 

Thirdly, Soininen and Luoto (2014) “assembled over 4900 published AUC (area under the curve of a receiver operating characteristic plot) values” to examine the predictability of SDM in relation to species traits. 
Having conducted this labour intensive review they suggested that researchers should “give precise reports of model calibration and evaluation methods” to enable subsequent met analyses. 
Relatedly, the methodological review of Yackulic et al. (2012) investigated the use of the MAXENT algorithm in 108 articles, and have a similar concern regarding the “transparency and usefulness” in the reporting of SDM. 
In these studies there is little to no opportunity afforded by the original studies to investigate the sensitivity of the conclusion to choices in model building and data selection. 
These studies point to a far wider reduction in scientific productivity due to reporting of SDM as ‘closed knowledge’.

These three scenarios are illustrative of some of the need for the data and modelling aspects of SDM to become more repeatable, reproducible, accessible, modifiable and updateable. Each are crucial examples of the barriers to this science.
Science has to be this way and written statements of the modelling carried out do not facilitate a productive science. 
SDM, as a science, is not extensible given current working practices. 

##### Past work and other software - the USP of ZOON and requirements

Most of the SDM users replying to a survey in 200X (Ahmed et al. 2015) were using either MaxEnt or R as the first choice software for their analyses. The software market is much diverse, however, including a variety of software developed specifically for SDM (e.g. MaxEnt (), the BioMod () and dismo () packages for R, SDMtoolbox (Brown 2014), openModeller (), BioEnsembles (), ModEco ()) and software that has been appropriated for SDM studies, such as statistical software (R (), WinBugs (), OpenBugs (), Python()) and other less general software  (Domain (), Canoco (), MARS()). 
Reproducibility (and the issues discussed above) were not a primary requirement of these software, and whilst some have the capacity for an analysis to be repeated, many do not. 
Software such as BioMod, OpenModeller, BioEnsembles, ModEco were developed to enable users to carry out analyses with multiple models.
The BIOVEL software (De Giovanni et al. 2015) is an exception, sharing many of the general principles of ZOON, such as the increased accessibility to science via community contributed resources and increased sustainability by creating an e-infrastructure for this science. 
There are other workflow systems that can be used to wrap around SDM analyses (e.g. Kepler, Vis-Trails, Taverna), yet there has not been a large uptake by the community. P
erhaps this is because of the unfamiliarity or assumed complexity of these tools. 
The SDM package (Naimi & Araujo 2016) has some functionality for users to incorporate new modelling methods into their analyses.

<!-- The Solution: ZOOOOOON!  -->
The `zoon` R package encodes SDM analyses as a simple workflow of five steps: obtaining occurrence data, obtaining covariate data, pre-processing these data, fitting a model, and generating outputs.
Each of these steps is carried out by one or more community-contributed software modules. 
This framework facilitates rapid dissemination of novel SDM methodologies by lowering the bar to creating research software.
`zoon` workflows are re-runnable records of the data, code and results of an entire SDM analysis and can be easily reproduced, scrutinized and extended by the whole research community.

ZOON allows users to make use of modules whether they are using a ZOON workflow or not. 
Users can create new modules for any modelling method and integrate it into another analysis. 
Unlike R itself, there are far reduced overheads on creating a package...

 
<!-- How It Works -->
### Implementing a `zoon` workflow

Module types (and examples) in a diagram (Figure 1).

```{r, echo = FALSE, fig.cap = "The modular SDM structure encoded by a zoon workflow. A) Flow diagram representing the module types. B) The required inputs and outputs for each module types (full details given in the `zoon` vignette 'Building a module'). C) Chaining and listing modules of the same type. D) An example workflow, corresponding to Example 1 below."}

# set up plotting window
plot.new()
par(mar = rep(0, 4))
plot.window(0:1, 0:1)

# grey rectangle (no background in vector pdf?)
rect(-1, -1, 2, 2, col = grey(0.9), border = NA)

# text over the top
text(0.5, 0.5, 'PLACEHOLDER',
     col = grey(0.3),
     cex = 3,
     xpd = NA)
```

Structure of workflow objects:

* code (call and modules used)
* output of each module; data, results and intermediate steps
* recording the session info and package and module versions

Extra stuff workflows do (handle cross validation, run parallel methods/data comparisons).

Things you can do to workflows:

* visualise the structure
* execute whole thing from scratch (grabs new data from web)
* execute from part way through

Include a figure visualising the sturcutre of the workflow object and how it can be adopted in the ChangeWorkflow function (corresponding to an example below?).

### Example Applications

We demonstrate the `zoon` R package by recreating two SDM analyses from published research articles and extending them.
Workflow objects created by these analyses can be accessed at [http://figshare.com/articles/zoon_applications_paper_workflows](http://figshare.com/articles/zoon_applications_paper_workflows).
We encourage readers to download, interrogate and alter these workflows for themselves.
Full code and metadata for all of the modules used in the examples below, can be found at [https://github.com/zoonproject/modules/R](https://github.com/zoonproject/modules/R)

#### Re-running a fairly simple SDM, tweaking some different stuff and looking at the results 

Explanation & citation

One of the modules we had to write:

```{r, eval=FALSE}
AwesomeModule <- function(.df) {
    something
    return (something else)
}
```

What the workflow looks like

```{r, eval=FALSE}
carruthers_et_al <- workflow(
    occurrence = ...,
    covariate = ...,
    process = ...,
    model = ...,
    output = ...)
```

Some tweak we did to it:

```{r, eval=FALSE}
carruthers_et_al_interactive <- ReRunWorkflow(
    carruthers_et_al,
    output = InteractiveMap)
```

![The interactive map module overlay the raw data and predicted distribution, allowing users to interactivly explore thier results.](./figs/interactive_map.png)

Some plottable results of this analysis 

#### Repeating a MEE methods comparison 

Proposed paper:

>Merow & Silander (2014) A comparison of Maxlike and Maxent for modelling species distributions. *Methods in Ecology and Evolution*

This is a method that saw a lot of discussion and for which more experiments could be useful.

Possible experiments:
* evaluating with different criteria (e.g. deviance or pseudo-r-squared which measure calibration capacity)
* fitting the same models with GBIF data and evaluating against the BBS PA data,
* fitting/evaluating on spatially-stratified holdout data
* fitting the models with other species

(choose only one of these)


One of the modules we had to write (simpler than the MaxLike one!):

```{r, eval=FALSE}
CarolinaWrenPO <- function() {
  
  # load maxlike and the dataset into this environment
  zoon::GetPackage('maxlike')
  data(carw, envir = environment())
  occ <- na.omit(carw.data$pa.data)

  # keep only presences
  occ <- occ[occ$y == 1, ]
  
  # build the occurrence dataset and return
  data.frame(longitude = occ$Lon,
             latitude = occ$Lat,
             value = occ$y,
             type = 'presence'),
             fold = 1)
  
}
```

What the workflow looks like:

```{r, eval=FALSE}
merow_and_silander <- workflow(
    occurrence = CarolinaWrenPO,
    covariate = ...,
    process = ...,
    model = list(MaxEnt, MaxLike),
    output = ...)
```

So we ran it again with disc-based spatial stratification:

```{r, eval=FALSE}
merow_and_silander_spatial <- ReRunWorkflow(
    merow_and_silander,
    process = Chain(..., PartitionDisc))
```

### Future developments

Tutorials on how to create workflows and modules, as well as full technical details for module developers, are provided as vignettes distributed with `zoon`.

While the `zoon` R package can be used in isolation, future work will develop an online platform to facilitate exploring contributed modules and workflows.
This platform will also provide an online space to discuss, and openly evaluate, proposed best practices in SDM.
The zoon R package therefore represents a step towards a more reproducible ecosystem of SDM software. 


